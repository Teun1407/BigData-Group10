{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac89b040-fea7-4c74-a822-a9c87a46f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1137e7b-81bd-45c3-b720-cf2a6758c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined Dataset Loaded Successfully!\n",
      "Shape of Combined Dataset: (7959, 9)\n",
      "Columns:\n",
      " Index(['Unnamed: 0', 'tconst', 'primaryTitle', 'originalTitle', 'startYear',\n",
      "       'endYear', 'runtimeMinutes', 'numVotes', 'label'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing Values:\n",
      " Unnamed: 0           0\n",
      "tconst               0\n",
      "primaryTitle         0\n",
      "originalTitle     3988\n",
      "startYear            0\n",
      "endYear              0\n",
      "runtimeMinutes       0\n",
      "numVotes           790\n",
      "label                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tconst</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0010600</td>\n",
       "      <td>The Doll</td>\n",
       "      <td>Die Puppe</td>\n",
       "      <td>1919</td>\n",
       "      <td>\\N</td>\n",
       "      <td>66</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>tt0011841</td>\n",
       "      <td>Way Down East</td>\n",
       "      <td>Way Down East</td>\n",
       "      <td>1920</td>\n",
       "      <td>\\N</td>\n",
       "      <td>145</td>\n",
       "      <td>5376.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>tt0012494</td>\n",
       "      <td>Déstiny</td>\n",
       "      <td>Der müde Tod</td>\n",
       "      <td>1921</td>\n",
       "      <td>\\N</td>\n",
       "      <td>97</td>\n",
       "      <td>5842.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>tt0015163</td>\n",
       "      <td>The Navigator</td>\n",
       "      <td>The Navigator</td>\n",
       "      <td>1924</td>\n",
       "      <td>\\N</td>\n",
       "      <td>59</td>\n",
       "      <td>9652.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>tt0016220</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>1925</td>\n",
       "      <td>\\N</td>\n",
       "      <td>93</td>\n",
       "      <td>17887.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     tconst              primaryTitle             originalTitle  \\\n",
       "0           4  tt0010600                  The Doll                 Die Puppe   \n",
       "1           7  tt0011841             Way Down East             Way Down East   \n",
       "2           9  tt0012494                   Déstiny              Der müde Tod   \n",
       "3          25  tt0015163             The Navigator             The Navigator   \n",
       "4          38  tt0016220  The Phantom of the Opera  The Phantom of the Opera   \n",
       "\n",
       "  startYear endYear runtimeMinutes  numVotes  label  \n",
       "0      1919      \\N             66    1898.0   True  \n",
       "1      1920      \\N            145    5376.0   True  \n",
       "2      1921      \\N             97    5842.0   True  \n",
       "3      1924      \\N             59    9652.0   True  \n",
       "4      1925      \\N             93   17887.0   True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the dataset folder\n",
    "path = \"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/\"\n",
    "\n",
    "# Get all train files (train-1.csv to train-8.csv)\n",
    "file_paths = glob.glob(path + \"train-*.csv\")\n",
    "\n",
    "# Load all CSVs into a single DataFrame\n",
    "df_movies = pd.concat([pd.read_csv(file) for file in file_paths], ignore_index=True)\n",
    "\n",
    "# Check the structure\n",
    "print(\"✅ Combined Dataset Loaded Successfully!\")\n",
    "print(\"Shape of Combined Dataset:\", df_movies.shape)\n",
    "print(\"Columns:\\n\", df_movies.columns)\n",
    "\n",
    "# Display missing values count\n",
    "print(\"\\nMissing Values:\\n\", df_movies.isnull().sum())\n",
    "\n",
    "# Show first few rows\n",
    "df_movies.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a778699-9cd5-4697-a46f-6d2f064b6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Directors JSON Loaded Successfully!\n",
      "Columns: Index(['movie', 'director'], dtype='object')\n",
      "                                               movie  \\\n",
      "0  {'0': 'tt0003740', '1': 'tt0008663', '2': 'tt0...   \n",
      "\n",
      "                                            director  \n",
      "0  {'0': 'nm0665163', '1': 'nm0803705', '2': 'nm0...   \n",
      "\n",
      "✅ Writers JSON Loaded Successfully!\n",
      "Columns: Index(['movie', 'writer'], dtype='object')\n",
      "       movie     writer\n",
      "0  tt0003740  nm0195339\n",
      "1  tt0003740  nm0515385\n",
      "2  tt0003740  nm0665163\n",
      "3  tt0003740  nm0758215\n",
      "4  tt0008663  nm0406585\n",
      "\n",
      "Missing Values in Directors JSON:\n",
      " movie       0\n",
      "director    0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Writers JSON:\n",
      " movie     0\n",
      "writer    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Path to JSON files\n",
    "directing_path = \"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/directing.json\"\n",
    "writing_path = \"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/writing.json\"\n",
    "\n",
    "# Load JSON files into DuckDB\n",
    "con = duckdb.connect()\n",
    "df_directors = con.execute(f\"SELECT * FROM read_json_auto('{directing_path}')\").fetchdf()\n",
    "df_writers = con.execute(f\"SELECT * FROM read_json_auto('{writing_path}')\").fetchdf()\n",
    "\n",
    "# Check structure\n",
    "print(\"✅ Directors JSON Loaded Successfully!\")\n",
    "print(\"Columns:\", df_directors.columns)\n",
    "print(df_directors.head(), \"\\n\")\n",
    "\n",
    "print(\"✅ Writers JSON Loaded Successfully!\")\n",
    "print(\"Columns:\", df_writers.columns)\n",
    "print(df_writers.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Directors JSON:\\n\", df_directors.isnull().sum())\n",
    "print(\"\\nMissing Values in Writers JSON:\\n\", df_writers.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f85361-06fb-4f48-ae9c-d1bad22bd47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned Directors Data:\n",
      "tconst         0\n",
      "director_id    0\n",
      "dtype: int64 \n",
      "\n",
      "      tconst director_id\n",
      "0  tt0003740   nm0665163\n",
      "1  tt0008663   nm0803705\n",
      "2  tt0009369   nm0428059\n",
      "3  tt0009369   nm0949648\n",
      "4  tt0010307   nm0304098 \n",
      "\n",
      "✅ Cleaned Writers Data:\n",
      "tconst       0\n",
      "writer_id    0\n",
      "dtype: int64 \n",
      "\n",
      "      tconst  writer_id\n",
      "0  tt0003740  nm0195339\n",
      "1  tt0003740  nm0515385\n",
      "2  tt0003740  nm0665163\n",
      "3  tt0003740  nm0758215\n",
      "4  tt0008663  nm0406585\n",
      "\n",
      "✅ Cleaned `directing.json` and `writing.json` ready for merging!\n"
     ]
    }
   ],
   "source": [
    "# Ensure JSON files are correctly loaded\n",
    "df_directors = pd.read_json(\"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/directing.json\")\n",
    "df_writers = pd.read_json(\"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/writing.json\")\n",
    "\n",
    "# Rename 'movie' to 'tconst' for merging\n",
    "df_directors.rename(columns={\"movie\": \"tconst\", \"director\": \"director_id\"}, inplace=True)\n",
    "df_writers.rename(columns={\"movie\": \"tconst\", \"writer\": \"writer_id\"}, inplace=True)\n",
    "\n",
    "# Convert nested JSON fields into strings (fix unhashable type issue)\n",
    "df_directors[\"director_id\"] = df_directors[\"director_id\"].astype(str)\n",
    "df_writers[\"writer_id\"] = df_writers[\"writer_id\"].astype(str)\n",
    "\n",
    "# Drop duplicates\n",
    "df_directors.drop_duplicates(inplace=True)\n",
    "df_writers.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check missing values\n",
    "print(\"✅ Cleaned Directors Data:\")\n",
    "print(df_directors.isnull().sum(), \"\\n\")\n",
    "print(df_directors.head(), \"\\n\")\n",
    "\n",
    "print(\"✅ Cleaned Writers Data:\")\n",
    "print(df_writers.isnull().sum(), \"\\n\")\n",
    "print(df_writers.head())\n",
    "\n",
    "# Save cleaned versions in DuckDB for merging\n",
    "import duckdb\n",
    "con = duckdb.connect()\n",
    "con.register(\"directors\", df_directors)\n",
    "con.register(\"writers\", df_writers)\n",
    "\n",
    "print(\"\\n✅ Cleaned `directing.json` and `writing.json` ready for merging!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e1b624-e61d-422f-9dc5-bfb75eb4dbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Merged dataset saved as 'merged_cleaned_data.csv' successfully!\n"
     ]
    }
   ],
   "source": [
    "# Register df_movies in DuckDB\n",
    "con = duckdb.connect()\n",
    "con.register(\"movies\", df_movies)\n",
    "con.register(\"directors\", df_directors)\n",
    "con.register(\"writers\", df_writers)\n",
    "\n",
    "# Perform the LEFT JOIN to merge director_id and writer_id\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    movies.*, \n",
    "    directors.director_id, \n",
    "    writers.writer_id\n",
    "FROM movies\n",
    "LEFT JOIN directors ON movies.tconst = directors.tconst\n",
    "LEFT JOIN writers ON movies.tconst = writers.tconst\n",
    "\"\"\"\n",
    "\n",
    "# Run query and get final merged dataset\n",
    "df_merged = con.execute(query).fetchdf()\n",
    "\n",
    "# Save the merged dataset\n",
    "df_merged.to_csv(\"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/merged_cleaned_data.csv\", index=False)\n",
    "\n",
    "# Close DuckDB connection\n",
    "con.close()\n",
    "\n",
    "print(\"\\n✅ Merged dataset saved as 'merged_cleaned_data.csv' successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db2d540-fa13-4b08-a086-df7ebfe1ee7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Missing Values After Handling:\n",
      " tconst            0\n",
      "primaryTitle      0\n",
      "startYear         0\n",
      "runtimeMinutes    0\n",
      "numVotes          0\n",
      "label             0\n",
      "director_id       0\n",
      "writer_id         0\n",
      "dtype: int64\n",
      "\n",
      "✅ Final cleaned dataset saved as 'final_cleaned_data.csv' and ready for model training!\n"
     ]
    }
   ],
   "source": [
    "# Load merged dataset\n",
    "df = pd.read_csv(\"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/merged_cleaned_data.csv\")\n",
    "\n",
    "# Step 1: Drop unnecessary columns (if needed)\n",
    "columns_to_drop = [\"originalTitle\", \"endYear\", \"Unnamed: 0\"]  # Add more if necessary\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "\n",
    "## Handle missing values in numerical columns\n",
    "numeric_columns = [\"startYear\", \"runtimeMinutes\", \"numVotes\"]\n",
    "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors=\"coerce\")  # Ensure numeric format\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())  # Fill missing with median\n",
    "\n",
    "## Handle missing values in categorical columns\n",
    "df[\"director_id\"] = df[\"director_id\"].fillna(\"unknown\")\n",
    "df[\"writer_id\"] = df[\"writer_id\"].fillna(\"unknown\")\n",
    "\n",
    "# Step 3: Ensure correct data types\n",
    "df[\"startYear\"] = df[\"startYear\"].astype(int)\n",
    "df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].astype(int)\n",
    "df[\"numVotes\"] = df[\"numVotes\"].astype(int)\n",
    "\n",
    "# Step 4: Verify missing values are handled\n",
    "print(\"\\n✅ Missing Values After Handling:\\n\", df.isnull().sum())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv(\"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/final_cleaned_data.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Final cleaned dataset saved as 'final_cleaned_data.csv' and ready for model training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8ffcc0-a19f-4398-ae52-450af39983e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>startYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>label</th>\n",
       "      <th>director_id</th>\n",
       "      <th>writer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0010600</td>\n",
       "      <td>The Doll</td>\n",
       "      <td>1919</td>\n",
       "      <td>66</td>\n",
       "      <td>1898</td>\n",
       "      <td>True</td>\n",
       "      <td>nm0523932</td>\n",
       "      <td>nm0932559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0011841</td>\n",
       "      <td>Way Down East</td>\n",
       "      <td>1920</td>\n",
       "      <td>145</td>\n",
       "      <td>5376</td>\n",
       "      <td>True</td>\n",
       "      <td>nm0000428</td>\n",
       "      <td>nm0000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0012494</td>\n",
       "      <td>Déstiny</td>\n",
       "      <td>1921</td>\n",
       "      <td>97</td>\n",
       "      <td>5842</td>\n",
       "      <td>True</td>\n",
       "      <td>nm0000485</td>\n",
       "      <td>nm0902376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0015163</td>\n",
       "      <td>The Navigator</td>\n",
       "      <td>1924</td>\n",
       "      <td>59</td>\n",
       "      <td>9652</td>\n",
       "      <td>True</td>\n",
       "      <td>nm0000036</td>\n",
       "      <td>nm0369841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0016220</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>1925</td>\n",
       "      <td>93</td>\n",
       "      <td>17887</td>\n",
       "      <td>True</td>\n",
       "      <td>nm0781292</td>\n",
       "      <td>nm1541473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst              primaryTitle  startYear  runtimeMinutes  numVotes  \\\n",
       "0  tt0010600                  The Doll       1919              66      1898   \n",
       "1  tt0011841             Way Down East       1920             145      5376   \n",
       "2  tt0012494                   Déstiny       1921              97      5842   \n",
       "3  tt0015163             The Navigator       1924              59      9652   \n",
       "4  tt0016220  The Phantom of the Opera       1925              93     17887   \n",
       "\n",
       "   label director_id  writer_id  \n",
       "0   True   nm0523932  nm0932559  \n",
       "1   True   nm0000428  nm0000428  \n",
       "2   True   nm0000485  nm0902376  \n",
       "3   True   nm0000036  nm0369841  \n",
       "4   True   nm0781292  nm1541473  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a549107-4327-4789-bd56-07ade2e245ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data Split Successfully! Ready for Model Training.\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned dataset\n",
    "df = pd.read_csv(\"C:/Users/Gebruiker/Documents/UVA/Vakken met code/BD/BigData-Group10/imdb/final_cleaned_data.csv\")\n",
    "\n",
    "# Step 1: Select Features and Target\n",
    "features = [\"startYear\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\"]\n",
    "X = df[features]\n",
    "y = df[\"label\"]  # Target variable (binary classification)\n",
    "\n",
    "# Step 2: Train-Test Split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Preprocessing for Numeric & Categorical Data\n",
    "\n",
    "## Numeric Columns (Standardization)\n",
    "numeric_features = [\"startYear\", \"runtimeMinutes\", \"numVotes\"]\n",
    "\n",
    "## Categorical Columns (One-Hot Encoding)\n",
    "categorical_features = [\"director_id\", \"writer_id\"]\n",
    "\n",
    "## Preprocessing Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),  # Scale numeric features\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)  # Encode categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Data Split Successfully! Ready for Model Training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57fdf39-17ac-4b0f-aa90-b2b9aaa0a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Logistic Regression Model Accuracy: 0.8853\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.92      0.89      2273\n",
      "        True       0.91      0.85      0.88      2270\n",
      "\n",
      "    accuracy                           0.89      4543\n",
      "   macro avg       0.89      0.89      0.89      4543\n",
      "weighted avg       0.89      0.89      0.89      4543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Create a Pipeline for Preprocessing + Logistic Regression\n",
    "model_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))  # Ensure convergence\n",
    "])\n",
    "\n",
    "# Step 2: Train the Model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Make Predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n✅ Logistic Regression Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c6bea75-c428-4eda-9b50-70433ef2633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Training Logistic Regression...\n",
      "✅ Logistic Regression Accuracy: 0.8853\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.92      0.89      2273\n",
      "        True       0.91      0.85      0.88      2270\n",
      "\n",
      "    accuracy                           0.89      4543\n",
      "   macro avg       0.89      0.89      0.89      4543\n",
      "weighted avg       0.89      0.89      0.89      4543\n",
      "\n",
      "\n",
      "🔹 Training Random Forest...\n",
      "✅ Random Forest Accuracy: 0.9227\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.95      0.92      2273\n",
      "        True       0.94      0.90      0.92      2270\n",
      "\n",
      "    accuracy                           0.92      4543\n",
      "   macro avg       0.92      0.92      0.92      4543\n",
      "weighted avg       0.92      0.92      0.92      4543\n",
      "\n",
      "\n",
      "🔹 Training SVM...\n",
      "✅ SVM Accuracy: 0.9311\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.94      0.93      2273\n",
      "        True       0.94      0.92      0.93      2270\n",
      "\n",
      "    accuracy                           0.93      4543\n",
      "   macro avg       0.93      0.93      0.93      4543\n",
      "weighted avg       0.93      0.93      0.93      4543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define models to compare\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"linear\", probability=True)  # Linear Kernel for Binary Classification\n",
    "}\n",
    "\n",
    "# Step 2: Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔹 Training {name}...\")\n",
    "\n",
    "    # Create pipeline with preprocessing + model\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "\n",
    "    # Train model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"✅ {name} Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137d16f-5d06-4d37-b97e-2c98aab669e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f53d39-93c0-4427-80f5-c89204fda422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89519766-06ee-4d97-a56f-d357053c0b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
