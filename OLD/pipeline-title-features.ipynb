{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8224cfca-63cd-4397-8a7d-892f1b0577d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import trim_mean"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_runtime(df, k=0.1):\n",
    "    \"\"\"\n",
    "    Preprocesses the runtime information, including handling extreme values\n",
    "    (movies with runtime > 1000 minutes, possibly in seconds or hours).\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame containing the movie data.\n",
    "    - k: Proportion of values to trim from each end when computing the trimmed mean.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with cleaned runtime information.\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle movies that are possibly in seconds or hours\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].apply(lambda x: x / 60 if x > 1000 else x)  # Convert seconds to minutes\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].apply(lambda x: x * 60 if x < 5 else x)  # Convert minutes to hours if under 5 mins\n",
    "\n",
    "    # Compute k-trimmed mean for runtimeMinutes (ignoring NaN values)\n",
    "    trimmed_mean_runtime = trim_mean(df[\"runtimeMinutes\"].dropna(), proportiontocut=k)\n",
    "\n",
    "    print(trimmed_mean_runtime)\n",
    "\n",
    "    # Fill missing values with trimmed mean\n",
    "    df[\"runtimeMinutes\"].fillna(trimmed_mean_runtime)\n",
    "\n",
    "    return df"
   ],
   "id": "de8bce70a1f5acf2"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1588593-ab24-49a5-bb51-d755af920960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imdb_data(data_path, directors_path, writers_path):\n",
    "    \"\"\"\n",
    "    General preprocessing pipeline for IMDB data.\n",
    "    \n",
    "    Arguments:\n",
    "    - data_path: Path to the train/test/validation data CSV file.\n",
    "    - directors_path: Path to the directing.json file.\n",
    "    - writers_path: Path to the writing.json file.\n",
    "    \n",
    "    Returns:\n",
    "    - Cleaned Pandas DataFrame ready for model training or prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Load main dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Step 2: Load JSON files (Directors & Writers)\n",
    "    df_directors = pd.read_json(directors_path)\n",
    "    df_writers = pd.read_json(writers_path)\n",
    "\n",
    "    # Step 3: Rename columns for consistency\n",
    "    df_directors.rename(columns={\"movie\": \"tconst\", \"director\": \"director_id\"}, inplace=True)\n",
    "    df_writers.rename(columns={\"movie\": \"tconst\", \"writer\": \"writer_id\"}, inplace=True)\n",
    "\n",
    "    # Step 4: Convert nested JSON fields into strings\n",
    "    df_directors[\"director_id\"] = df_directors[\"director_id\"].astype(str)\n",
    "    df_writers[\"writer_id\"] = df_writers[\"writer_id\"].astype(str)\n",
    "\n",
    "    # Step 5: Merge main dataset with Directors & Writers using DuckDB\n",
    "    con = duckdb.connect()\n",
    "    con.register(\"movies\", df)\n",
    "    con.register(\"directors\", df_directors)\n",
    "    con.register(\"writers\", df_writers)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        movies.*, \n",
    "        directors.director_id, \n",
    "        writers.writer_id\n",
    "    FROM movies\n",
    "    LEFT JOIN directors ON movies.tconst = directors.tconst\n",
    "    LEFT JOIN writers ON movies.tconst = writers.tconst\n",
    "    \"\"\"\n",
    "\n",
    "    df = con.execute(query).fetchdf()\n",
    "    con.close()\n",
    "\n",
    "    # Step 6: Create column year from startYear and endYear\n",
    "    df['startYear'] = df['startYear'].replace('\\\\N', np.nan).astype(float)\n",
    "    df['endYear'] = df['endYear'].replace('\\\\N', np.nan).astype(float)\n",
    "    df['Year'] = df['startYear'].fillna(df['endYear'])\n",
    "\n",
    "    # Step 7: Clean title names\n",
    "    def normalize_text(text):\n",
    "        if pd.isna(text):  # Handle missing values\n",
    "            return \"\"\n",
    "        text = str(text)\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')  # Remove accents\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "        return text.strip()\n",
    "\n",
    "    def clean_titles(row):\n",
    "        primary = row['primaryTitle'] if pd.notna(row['primaryTitle']) else ''\n",
    "        original = row['originalTitle'] if pd.notna(row['originalTitle']) else ''\n",
    "\n",
    "        if not primary:\n",
    "            primary = original\n",
    "\n",
    "        cleaned_title = normalize_text(primary)\n",
    "\n",
    "        return cleaned_title if cleaned_title else \"Unknown Title\"\n",
    "\n",
    "    df['primaryTitle'] = df.apply(clean_titles, axis=1)\n",
    "    df.rename(columns={'primaryTitle': 'movieTitle'}, inplace=True)\n",
    "\n",
    "    # Step 8: Compute Title Uniqueness Score\n",
    "    title_counts = df[\"movieTitle\"].value_counts()\n",
    "    df[\"title_uniqueness\"] = df[\"movieTitle\"].apply(lambda x: 1 / title_counts[x] if title_counts[x] > 1 else 1)\n",
    "\n",
    "    # Step 9: Compute Sentiment Score\n",
    "    df[\"sentiment_score\"] = df[\"movieTitle\"].astype(str).apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "    # Step 10: Count words in each title\n",
    "    df[\"word_count\"] = df[\"movieTitle\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "    #Step 11 title lenght\n",
    "    df[\"title_word_length_std\"] = df[\"movieTitle\"].apply(lambda x: np.std([len(word) for word in x.split()]) if len(x.split()) > 1 else 0)\n",
    "    \n",
    "    # Step 12: Drop unnecessary columns\n",
    "    columns_to_drop = [\"originalTitle\", \"endYear\", \"startYear\", \"Unnamed: 0\"]\n",
    "    df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "    # Step 13: Handle missing values\n",
    "    df = preprocess_runtime(df, 0.1)\n",
    "\n",
    "    # Step 14: Fill missing values for numVotes\n",
    "    trimmed_mean_votes = trim_mean(df[\"numVotes\"].dropna(), proportiontocut=0.1)\n",
    "    df[\"numVotes\"] = df[\"numVotes\"].fillna(trimmed_mean_votes)\n",
    "\n",
    "    # Step 15: Fill missing values for director_id and writer_id\n",
    "    df[\"director_id\"] = df[\"director_id\"].fillna(\"unknown\")\n",
    "    df[\"writer_id\"] = df[\"writer_id\"].fillna(\"unknown\")\n",
    "\n",
    "    # Step 16: Ensure correct data types\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].astype(int)\n",
    "    df[\"numVotes\"] = df[\"numVotes\"].astype(int)\n",
    "\n",
    "    # Step 17: Ensure each `tconst` is unique\n",
    "    df = df.groupby(\"tconst\").first().reset_index()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b782cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All datasets have been preprocessed and saved!\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "# Define the base directory\n",
    "base_data_dir = os.path.join(os.getcwd(), \"imdb\")\n",
    "\n",
    "# Generate the list of train file paths\n",
    "train_files = [os.path.join(base_data_dir, f) for f in os.listdir(base_data_dir) if f.startswith(\"train-\") and f.endswith(\".csv\")]\n",
    "\n",
    "# Define paths for directors and writers files\n",
    "directors_path = os.path.join(base_data_dir, \"directing.json\")\n",
    "writers_path = os.path.join(base_data_dir, \"writing.json\")\n",
    "\n",
    "# Load JSON files (Directors & Writers)\n",
    "df_directors = pd.read_json(directors_path)\n",
    "df_writers = pd.read_json(writers_path)\n",
    "\n",
    "# Preprocess and merge all training data\n",
    "df_train = pd.concat([preprocess_imdb_data(file, directors_path, writers_path) for file in train_files], ignore_index=True)\n",
    "\n",
    "# Preprocess validation and test data\n",
    "df_val = preprocess_imdb_data(os.path.join(base_data_dir, \"validation_hidden.csv\"), directors_path, writers_path)\n",
    "df_test = preprocess_imdb_data(os.path.join(base_data_dir, \"test_hidden.csv\"), directors_path, writers_path)\n",
    "\n",
    "# Save cleaned datasets\n",
    "df_train.to_csv(\"cleaned/final_training_data_titlefeatures.csv\", index=False)\n",
    "df_val.to_csv(\"cleaned/final_validation_data_titlefeatures.csv\", index=False)\n",
    "df_test.to_csv(\"cleaned/final_test_data_titlefeatures.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ All datasets have been preprocessed and saved!\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_unique_ratio(df, columns=None):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of unique rows to total rows in the DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame to analyze\n",
    "    - columns: List of columns to consider (if None, uses all columns)\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing unique ratio metrics\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "\n",
    "    total_rows = len(df)\n",
    "    unique_rows = len(df[columns].drop_duplicates())\n",
    "    ratio = unique_rows / total_rows\n",
    "\n",
    "    metrics = {\n",
    "        \"total_rows\": total_rows,\n",
    "        \"unique_rows\": unique_rows,\n",
    "        \"unique_ratio\": ratio\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Add this after your data preprocessing\n",
    "print(\"\\n🔍 Analyzing unique row ratios...\")\n",
    "\n",
    "# Calculate ratios for all datasets\n",
    "train_metrics = calculate_unique_ratio(df_train)\n",
    "val_metrics = calculate_unique_ratio(df_val)\n",
    "test_metrics = calculate_unique_ratio(df_test)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nUnique Row Analysis:\")\n",
    "print(f\"Training Data:\")\n",
    "print(f\"  - Total Rows: {train_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {train_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {train_metrics['unique_ratio']:.2%}\")\n",
    "\n",
    "print(f\"\\nValidation Data:\")\n",
    "print(f\"  - Total Rows: {val_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {val_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {val_metrics['unique_ratio']:.2%}\")\n",
    "\n",
    "print(f\"\\nTest Data:\")\n",
    "print(f\"  - Total Rows: {test_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {test_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {test_metrics['unique_ratio']:.2%}\")"
   ],
   "id": "2d42f0eed525e31a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def handle_duplicates(df, groupby_cols=None, agg_strategy=None):\n",
    "    \"\"\"\n",
    "    Handle duplicate rows using specified aggregation strategies.\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame to process\n",
    "    - groupby_cols: List of columns to identify duplicates (default: all columns except label)\n",
    "    - agg_strategy: Dictionary of column names and aggregation functions\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with handled duplicates\n",
    "    \"\"\"\n",
    "    if groupby_cols is None:\n",
    "        groupby_cols = [col for col in df.columns if col != 'label']\n",
    "\n",
    "    if agg_strategy is None:\n",
    "        agg_strategy = {\n",
    "            'runtimeMinutes': 'mean',\n",
    "            'numVotes': 'sum',\n",
    "            'startYear': 'first',\n",
    "            'director_id': 'first',\n",
    "            'writer_id': 'first',\n",
    "            'label': 'mode'\n",
    "        }\n",
    "\n",
    "    # Count occurrences before deduplication\n",
    "    total_rows = len(df)\n",
    "    unique_rows = len(df[groupby_cols].drop_duplicates())\n",
    "\n",
    "    if total_rows == unique_rows:\n",
    "        print(\"No duplicates found!\")\n",
    "        return df\n",
    "\n",
    "    print(f\"\\nFound {total_rows - unique_rows:,} duplicate rows\")\n",
    "    print(f\"Unique ratio before: {(unique_rows/total_rows):.2%}\")\n",
    "\n",
    "    # Handle duplicates using aggregation\n",
    "    df_cleaned = df.groupby(groupby_cols, as_index=False).agg(agg_strategy)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Rows after duplicate handling: {len(df_cleaned):,}\")\n",
    "    print(f\"Unique ratio after: {(len(df_cleaned)/total_rows):.2%}\")\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Handle duplicates\n",
    "print(\"\\n🔍 Handling duplicates...\")\n",
    "df_train = handle_duplicates(df_train)\n",
    "df_val = handle_duplicates(df_val)\n",
    "df_test = handle_duplicates(df_test)"
   ],
   "id": "e8e86c7b646b0ea0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4931c9-d175-44ed-8e4d-2963d66be56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training model on full training data...\n",
      "✅ Predictions saved for submission!\n"
     ]
    }
   ],
   "source": [
    "# # Define Features & Target\n",
    "# features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\", \"word_count\"]\n",
    "# X_train = df_train[features]\n",
    "# y_train = df_train[\"label\"]\n",
    "# X_val = df_val[features]\n",
    "# X_test = df_test[features]\n",
    "\n",
    "# # Preprocessing Pipeline\n",
    "# numeric_features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"word_count\"]\n",
    "# categorical_features = [\"director_id\", \"writer_id\"]\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", StandardScaler(), numeric_features),\n",
    "#         (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Train Logistic Regression Model\n",
    "# model = Pipeline([\n",
    "#     (\"preprocessing\", preprocessor),\n",
    "#     (\"classifier\", SVC(kernel=\"linear\", probability=True))\n",
    "# ])\n",
    "\n",
    "# print(\"🔹 Training model on full training data...\")\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Generate Predictions\n",
    "# y_val_pred = model.predict(X_val)\n",
    "# y_test_pred = model.predict(X_test)\n",
    "\n",
    "# # Save predictions in required format (no headers, single column)\n",
    "# pd.DataFrame(y_val_pred).to_csv(\"submissions/validation_predictions_SVM.csv\", index=False, header=False)\n",
    "# pd.DataFrame(y_test_pred).to_csv(\"submissions/test_predictions_SVM.csv\", index=False, header=False)\n",
    "\n",
    "# print(\"✅ Predictions saved for submission!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90c25ca6-e414-426c-9b66-901333d1d979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training Accuracy: 0.7105\n",
      "✅ Validation Accuracy: 0.7161\n",
      "📊 Classification Report for:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.77      0.74       820\n",
      "        True       0.73      0.66      0.69       772\n",
      "\n",
      "    accuracy                           0.72      1592\n",
      "   macro avg       0.72      0.71      0.71      1592\n",
      "weighted avg       0.72      0.72      0.71      1592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed training dataset\n",
    "df_train = pd.read_csv(\"cleaned/final_training_data_titlefeatures.csv\")\n",
    "\n",
    "# Apply frequency encoding to categorical variables\n",
    "for col in [\"director_id\", \"writer_id\"]:\n",
    "    freq_encoding = df_train[col].value_counts(normalize=True)\n",
    "    df_train[col] = df_train[col].map(freq_encoding)\n",
    "\n",
    "# Define Features & Target\n",
    "features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\", \"word_count\", \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "X = df_train[features]\n",
    "y = df_train[\"label\"]  # Only train data has labels\n",
    "\n",
    "# **NEW: Split training data into train (80%) and validation (20%)**\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing Pipeline (same for all models)\n",
    "numeric_features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"word_count\", \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ]\n",
    ")\n",
    "# Create pipeline with preprocessing\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", SVC(kernel=\"linear\", probability=True))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"✅ Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"✅ Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"📊 Classification Report for:\\n\", classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02ac3f-4944-4f00-ad28-823e85a97f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
