{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8224cfca-63cd-4397-8a7d-892f1b0577d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:36.202640Z",
     "start_time": "2025-03-17T21:06:35.836977Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MultiLabelBinarizer  # One-hot encoding\n",
    "from scipy.stats import trim_mean\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from imdb import IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de8bce70a1f5acf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:36.207492Z",
     "start_time": "2025-03-17T21:06:36.205263Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_runtime(df, k=0.1):\n",
    "    \"\"\"\n",
    "    Preprocesses the runtime information, including handling extreme values\n",
    "    (movies with runtime > 1000 minutes, possibly in seconds or hours).\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame containing the movie data.\n",
    "    - k: Proportion of values to trim from each end when computing the trimmed mean.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with cleaned runtime information.\n",
    "    \"\"\"\n",
    "    # First convert to numeric, coercing errors to NaN\n",
    "    df[\"runtimeMinutes\"] = pd.to_numeric(df[\"runtimeMinutes\"], errors='coerce')\n",
    "\n",
    "    # Compute k-trimmed mean for runtimeMinutes (ignoring NaN values)\n",
    "    trimmed_mean_runtime = trim_mean(df[\"runtimeMinutes\"].dropna().values, proportiontocut=k)\n",
    "    print(trimmed_mean_runtime)\n",
    "\n",
    "    # Fill missing values with trimmed mean\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].fillna(trimmed_mean_runtime)\n",
    "\n",
    "    # Handle movies that are possibly in seconds or hours\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].apply(lambda x: x / 60 if pd.notna(x) and x > 1000 else x)  # Convert seconds to minutes\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].apply(lambda x: x * 60 if pd.notna(x) and x < 5 else x)  # Convert minutes to hours if under 5 mins\n",
    "\n",
    "    # Now convert to int (after handling extreme values and filling NaNs)\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].round().astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda025d4-02c1-4a13-b93c-0028a48a0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IMDbPY\n",
    "ia = IMDb()\n",
    "\n",
    "def fetch_movie_genre(title, genre_cache):\n",
    "    \"\"\"\n",
    "    Fetch movie genre using IMDbPY.\n",
    "    \n",
    "    Arguments:\n",
    "    - title: Cleaned movie title.\n",
    "    - genre_cache: Dictionary to store already fetched genres to avoid duplicate API calls.\n",
    "    \n",
    "    Returns:\n",
    "    - List of genres if found, otherwise [\"Unknown\"].\n",
    "    \"\"\"\n",
    "    if title in genre_cache:  # Check cache first\n",
    "        return genre_cache[title]\n",
    "\n",
    "    try:\n",
    "        movies = ia.search_movie(title)\n",
    "        if movies:\n",
    "            movie = movies[0]  # Get the first search result\n",
    "            ia.update(movie)  # Fetch full details\n",
    "            genre_list = movie.get('genres', [\"Unknown\"])\n",
    "            genre_cache[title] = genre_list  # Store in cache as a list\n",
    "            return genre_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching genre for {title}: {e}\")\n",
    "    \n",
    "    genre_cache[title] = [\"Unknown\"]\n",
    "    return [\"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1588593-ab24-49a5-bb51-d755af920960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:36.288475Z",
     "start_time": "2025-03-17T21:06:36.283702Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_imdb_data(data_path, directors_path, writers_path):\n",
    "    \"\"\"\n",
    "    General preprocessing pipeline for IMDB data.\n",
    "    \n",
    "    Arguments:\n",
    "    - data_path: Path to the train/test/validation data CSV file.\n",
    "    - directors_path: Path to the directing.json file.\n",
    "    - writers_path: Path to the writing.json file.\n",
    "    \n",
    "    Returns:\n",
    "    - Cleaned Pandas DataFrame ready for model training or prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Load main dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Step 2: Load JSON files (Directors & Writers)\n",
    "    df_directors = pd.read_json(directors_path)\n",
    "    df_writers = pd.read_json(writers_path)\n",
    "\n",
    "    # Step 3: Rename columns for consistency\n",
    "    df_directors.rename(columns={\"movie\": \"tconst\", \"director\": \"director_id\"}, inplace=True)\n",
    "    df_writers.rename(columns={\"movie\": \"tconst\", \"writer\": \"writer_id\"}, inplace=True)\n",
    "\n",
    "    # Step 4: Convert nested JSON fields into strings\n",
    "    df_directors[\"director_id\"] = df_directors[\"director_id\"].astype(str)\n",
    "    df_writers[\"writer_id\"] = df_writers[\"writer_id\"].astype(str)\n",
    "\n",
    "    # Step 5: Merge main dataset with Directors & Writers using DuckDB\n",
    "    con = duckdb.connect()\n",
    "    con.register(\"movies\", df)\n",
    "    con.register(\"directors\", df_directors)\n",
    "    con.register(\"writers\", df_writers)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        movies.*, \n",
    "        directors.director_id, \n",
    "        writers.writer_id\n",
    "    FROM movies\n",
    "    LEFT JOIN directors ON movies.tconst = directors.tconst\n",
    "    LEFT JOIN writers ON movies.tconst = writers.tconst\n",
    "    \"\"\"\n",
    "\n",
    "    df = con.execute(query).fetchdf()\n",
    "    con.close()\n",
    "\n",
    "    # Step 6: Create column year from startYear and endYear\n",
    "    df['startYear'] = df['startYear'].replace('\\\\N', np.nan).astype(float)\n",
    "    df['endYear'] = df['endYear'].replace('\\\\N', np.nan).astype(float)\n",
    "    df['Year'] = df['startYear'].fillna(df['endYear'])\n",
    "\n",
    "    # Step 7: Clean title names\n",
    "    def normalize_text(text):\n",
    "        if pd.isna(text):  # Handle missing values\n",
    "            return \"\"\n",
    "        text = str(text)\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')  # Remove accents\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "        return text.strip()\n",
    "\n",
    "    def clean_titles(row):\n",
    "        primary = row['primaryTitle'] if pd.notna(row['primaryTitle']) else ''\n",
    "        original = row['originalTitle'] if pd.notna(row['originalTitle']) else ''\n",
    "\n",
    "        if not primary:\n",
    "            primary = original\n",
    "\n",
    "        cleaned_title = normalize_text(primary)\n",
    "\n",
    "        return cleaned_title if cleaned_title else \"Unknown Title\"\n",
    "\n",
    "    df['primaryTitle'] = df.apply(clean_titles, axis=1)\n",
    "    df.rename(columns={'primaryTitle': 'movieTitle'}, inplace=True)\n",
    "\n",
    "    # Step 8: Compute Title Uniqueness Score\n",
    "    title_counts = df[\"movieTitle\"].value_counts()\n",
    "    df[\"title_uniqueness\"] = df[\"movieTitle\"].apply(lambda x: 1 / title_counts[x] if title_counts[x] > 1 else 1)\n",
    "\n",
    "    # Step 9: Compute Sentiment Score\n",
    "    df[\"sentiment_score\"] = df[\"movieTitle\"].astype(str).apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "    # Step 10: Count words in each title\n",
    "    df[\"word_count\"] = df[\"movieTitle\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Step 11: Compute title length standard deviation\n",
    "    df[\"title_word_length_std\"] = df[\"movieTitle\"].apply(lambda x: np.std([len(word) for word in x.split()]) if len(x.split()) > 1 else 0)\n",
    "    \n",
    "    # Step 12: Fetch Movie Genre using IMDbPY (Parallelized)\n",
    "    genre_cache = {}  # Dictionary to cache fetched genres\n",
    "    unique_titles = df[\"movieTitle\"].unique()  # Get unique movie titles\n",
    "\n",
    "    # Parallel processing to fetch genres faster\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        genres = list(executor.map(lambda title: fetch_movie_genre(title, genre_cache), unique_titles))\n",
    "\n",
    "    # Map fetched genres back to the dataframe\n",
    "    genre_map = dict(zip(unique_titles, genres))\n",
    "    df[\"genre\"] = df[\"movieTitle\"].map(genre_map)\n",
    "\n",
    "    # Step 13: One-Hot Encode Genres\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    genre_encoded = mlb.fit_transform(df[\"genre\"])  # Convert list of genres into binary matrix\n",
    "\n",
    "    # Create DataFrame with one-hot encoded genre columns\n",
    "    genre_df = pd.DataFrame(genre_encoded, columns=mlb.classes_, index=df.index)\n",
    "\n",
    "    # Merge with main DataFrame\n",
    "    df = pd.concat([df, genre_df], axis=1)\n",
    "\n",
    "    # Step 14: Drop unnecessary columns\n",
    "    columns_to_drop = [\"originalTitle\", \"endYear\", \"startYear\", \"Unnamed: 0\", \"genre\"]\n",
    "    df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "    # Step 15: Handle missing values\n",
    "    df = preprocess_runtime(df, 0.1)\n",
    "\n",
    "    # Step 16: Fill missing values for numVotes\n",
    "    trimmed_mean_votes = trim_mean(df[\"numVotes\"].dropna(), proportiontocut=0.1)\n",
    "    df[\"numVotes\"] = df[\"numVotes\"].fillna(trimmed_mean_votes)\n",
    "\n",
    "    # Step 17: Fill missing values for director_id and writer_id\n",
    "    df[\"director_id\"] = df[\"director_id\"].fillna(\"unknown\")\n",
    "    df[\"writer_id\"] = df[\"writer_id\"].fillna(\"unknown\")\n",
    "\n",
    "    # Step 18: Ensure correct data types\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"numVotes\"] = df[\"numVotes\"].astype(int)\n",
    "\n",
    "    # Step 19: Ensure each `tconst` is unique\n",
    "    df = df.groupby(\"tconst\").first().reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b782cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:37.987480Z",
     "start_time": "2025-03-17T21:06:36.295754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.14328808446456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 12:30:48,799 CRITICAL [imdbpy] C:\\Users\\Gebruiker\\Documents\\UVA\\Vakken met code\\BD\\BigData-Group10\\BD_env\\Lib\\site-packages\\imdb\\_exceptions.py:32: IMDbDataAccessError exception raised; args: ({'errcode': None, 'errmsg': 'None', 'url': 'https://www.imdb.com/find/?q=1&s=tt', 'proxy': '', 'exception type': 'IOError', 'original exception': <HTTPError 500: 'Internal Server Error'>},); kwds: {}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gebruiker\\Documents\\UVA\\Vakken met code\\BD\\BigData-Group10\\BD_env\\Lib\\site-packages\\imdb\\parser\\http\\__init__.py\", line 233, in retrieve_unicode\n",
      "    response = uopener.open(url)\n",
      "  File \"C:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py\", line 495, in open\n",
      "    response = meth(req, response)\n",
      "  File \"C:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py\", line 604, in http_response\n",
      "    response = self.parent.error(\n",
      "        'http', request, response, code, msg, hdrs)\n",
      "  File \"C:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py\", line 533, in error\n",
      "    return self._call_chain(*args)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"C:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py\", line 466, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py\", line 613, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 500: Internal Server Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching genre for 1: {'errcode': None, 'errmsg': 'None', 'url': 'https://www.imdb.com/find/?q=1&s=tt', 'proxy': '', 'exception type': 'IOError', 'original exception': <HTTPError 500: 'Internal Server Error'>}\n",
      "102.62376237623762\n",
      "109.99336650082918\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "# Define the base directory\n",
    "base_data_dir = os.path.join(os.getcwd(), \"imdb\")\n",
    "\n",
    "# Generate the list of train file paths\n",
    "train_files = [os.path.join(base_data_dir, f) for f in os.listdir(base_data_dir) if f.startswith(\"train-\") and f.endswith(\".csv\")]\n",
    "\n",
    "# Define paths for directors and writers files\n",
    "directors_path = os.path.join(base_data_dir, \"directing.json\")\n",
    "writers_path = os.path.join(base_data_dir, \"writing.json\")\n",
    "\n",
    "# Load JSON files (Directors & Writers)\n",
    "df_directors = pd.read_json(directors_path)\n",
    "df_writers = pd.read_json(writers_path)\n",
    "\n",
    "# Preprocess and merge all training data\n",
    "df_train = pd.concat([preprocess_imdb_data(file, directors_path, writers_path) for file in train_files], ignore_index=True)\n",
    "\n",
    "# Preprocess validation and test data\n",
    "df_val = preprocess_imdb_data(os.path.join(base_data_dir, \"validation_hidden.csv\"), directors_path, writers_path)\n",
    "df_test = preprocess_imdb_data(os.path.join(base_data_dir, \"test_hidden.csv\"), directors_path, writers_path)\n",
    "\n",
    "# Save cleaned datasets\n",
    "df_train.to_csv(\"cleaned/final_training_data_genre.csv\", index=False)\n",
    "df_val.to_csv(\"cleaned/final_validation_data_genre.csv\", index=False)\n",
    "df_test.to_csv(\"cleaned/final_test_data_genre.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ All datasets have been preprocessed and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42f0eed525e31a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:38.006849Z",
     "start_time": "2025-03-17T21:06:37.995760Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_unique_ratio(df, columns=None):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of unique rows to total rows in the DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame to analyze\n",
    "    - columns: List of columns to consider (if None, uses all columns)\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing unique ratio metrics\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "\n",
    "    total_rows = len(df)\n",
    "    unique_rows = len(df[columns].drop_duplicates())\n",
    "    ratio = unique_rows / total_rows\n",
    "\n",
    "    metrics = {\n",
    "        \"total_rows\": total_rows,\n",
    "        \"unique_rows\": unique_rows,\n",
    "        \"unique_ratio\": ratio\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Add this after your data preprocessing\n",
    "print(\"\\nüîç Analyzing unique row ratios...\")\n",
    "\n",
    "# Calculate ratios for all datasets\n",
    "train_metrics = calculate_unique_ratio(df_train)\n",
    "val_metrics = calculate_unique_ratio(df_val)\n",
    "test_metrics = calculate_unique_ratio(df_test)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nUnique Row Analysis:\")\n",
    "print(f\"Training Data:\")\n",
    "print(f\"  - Total Rows: {train_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {train_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {train_metrics['unique_ratio']:.2%}\")\n",
    "\n",
    "print(f\"\\nValidation Data:\")\n",
    "print(f\"  - Total Rows: {val_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {val_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {val_metrics['unique_ratio']:.2%}\")\n",
    "\n",
    "print(f\"\\nTest Data:\")\n",
    "print(f\"  - Total Rows: {test_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {test_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {test_metrics['unique_ratio']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e86c7b646b0ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:38.024352Z",
     "start_time": "2025-03-17T21:06:38.014177Z"
    }
   },
   "outputs": [],
   "source": [
    "def handle_duplicates(df, groupby_cols=None, agg_strategy=None):\n",
    "    \"\"\"\n",
    "    Handle duplicate rows using specified aggregation strategies.\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame to process\n",
    "    - groupby_cols: List of columns to identify duplicates (default: all columns except label)\n",
    "    - agg_strategy: Dictionary of column names and aggregation functions\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with handled duplicates\n",
    "    \"\"\"\n",
    "    if groupby_cols is None:\n",
    "        groupby_cols = [col for col in df.columns if col != 'label']\n",
    "\n",
    "    if agg_strategy is None:\n",
    "        agg_strategy = {\n",
    "            'runtimeMinutes': 'mean',\n",
    "            'numVotes': 'sum',\n",
    "            'startYear': 'first',\n",
    "            'director_id': 'first',\n",
    "            'writer_id': 'first',\n",
    "            'label': 'mode'\n",
    "        }\n",
    "\n",
    "    # Count occurrences before deduplication\n",
    "    total_rows = len(df)\n",
    "    unique_rows = len(df[groupby_cols].drop_duplicates())\n",
    "\n",
    "    if total_rows == unique_rows:\n",
    "        print(\"No duplicates found!\")\n",
    "        return df\n",
    "\n",
    "    print(f\"\\nFound {total_rows - unique_rows:,} duplicate rows\")\n",
    "    print(f\"Unique ratio before: {(unique_rows/total_rows):.2%}\")\n",
    "\n",
    "    # Handle duplicates using aggregation\n",
    "    df_cleaned = df.groupby(groupby_cols, as_index=False).agg(agg_strategy)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Rows after duplicate handling: {len(df_cleaned):,}\")\n",
    "    print(f\"Unique ratio after: {(len(df_cleaned)/total_rows):.2%}\")\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Handle duplicates\n",
    "print(\"\\nüîç Handling duplicates...\")\n",
    "df_train = handle_duplicates(df_train)\n",
    "df_val = handle_duplicates(df_val)\n",
    "df_test = handle_duplicates(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4931c9-d175-44ed-8e4d-2963d66be56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:38.032341Z",
     "start_time": "2025-03-17T21:06:38.030804Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Define Features & Target\n",
    "# features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\", \"word_count\"]\n",
    "# X_train = df_train[features]\n",
    "# y_train = df_train[\"label\"]\n",
    "# X_val = df_val[features]\n",
    "# X_test = df_test[features]\n",
    "\n",
    "# # Preprocessing Pipeline\n",
    "# numeric_features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"word_count\"]\n",
    "# categorical_features = [\"director_id\", \"writer_id\"]\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", StandardScaler(), numeric_features),\n",
    "#         (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Train Logistic Regression Model\n",
    "# model = Pipeline([\n",
    "#     (\"preprocessing\", preprocessor),\n",
    "#     (\"classifier\", SVC(kernel=\"linear\", probability=True))\n",
    "# ])\n",
    "\n",
    "# print(\"üîπ Training model on full training data...\")\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Generate Predictions\n",
    "# y_val_pred = model.predict(X_val)\n",
    "# y_test_pred = model.predict(X_test)\n",
    "\n",
    "# # Save predictions in required format (no headers, single column)\n",
    "# pd.DataFrame(y_val_pred).to_csv(\"submissions/validation_predictions_SVM.csv\", index=False, header=False)\n",
    "# pd.DataFrame(y_test_pred).to_csv(\"submissions/test_predictions_SVM.csv\", index=False, header=False)\n",
    "\n",
    "# print(\"‚úÖ Predictions saved for submission!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90c25ca6-e414-426c-9b66-901333d1d979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:40.403506Z",
     "start_time": "2025-03-17T21:06:38.038952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training Accuracy: 0.7140\n",
      "‚úÖ Validation Accuracy: 0.7142\n",
      "üìä Classification Report for:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.80      0.74       799\n",
      "        True       0.76      0.63      0.69       793\n",
      "\n",
      "    accuracy                           0.71      1592\n",
      "   macro avg       0.72      0.71      0.71      1592\n",
      "weighted avg       0.72      0.71      0.71      1592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed training dataset\n",
    "df_train = pd.read_csv(\"cleaned/final_training_data_titlefeatures.csv\")\n",
    "\n",
    "# Apply frequency encoding to categorical variables\n",
    "for col in [\"director_id\", \"writer_id\"]:\n",
    "    freq_encoding = df_train[col].value_counts(normalize=True)\n",
    "    df_train[col] = df_train[col].map(freq_encoding)\n",
    "\n",
    "# Define Features & Target\n",
    "features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\", \"word_count\", \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "X = df_train[features]\n",
    "y = df_train[\"label\"]  # Only train data has labels\n",
    "\n",
    "# **NEW: Split training data into train (80%) and validation (20%)**\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing Pipeline (same for all models)\n",
    "numeric_features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"word_count\", \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ]\n",
    ")\n",
    "# Create pipeline with preprocessing\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", SVC(kernel=\"linear\", probability=True))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"‚úÖ Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"‚úÖ Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"üìä Classification Report for:\\n\", classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed02ac3f-4944-4f00-ad28-823e85a97f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:07:54.381202Z",
     "start_time": "2025-03-17T21:07:27.133151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting grid search across classifiers...\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "‚úÖ Best parameters: {'classifier': LogisticRegression(max_iter=1000, random_state=42), 'classifier__C': 10.0, 'classifier__solver': 'liblinear'}\n",
      "‚úÖ Cross-validation accuracy: 0.7071\n",
      "‚úÖ Validation accuracy: 0.7205\n",
      "‚è±Ô∏è Time: 1.39 seconds\n",
      "\n",
      "Evaluating SVC...\n",
      "‚úÖ Best parameters: {'classifier': SVC(probability=True, random_state=42), 'classifier__C': 10.0, 'classifier__kernel': 'rbf'}\n",
      "‚úÖ Cross-validation accuracy: 0.7220\n",
      "‚úÖ Validation accuracy: 0.7205\n",
      "‚è±Ô∏è Time: 16.44 seconds\n",
      "\n",
      "Evaluating RandomForest...\n",
      "‚úÖ Best parameters: {'classifier': RandomForestClassifier(random_state=42), 'classifier__max_depth': 20, 'classifier__n_estimators': 100}\n",
      "‚úÖ Cross-validation accuracy: 0.7182\n",
      "‚úÖ Validation accuracy: 0.7255\n",
      "‚è±Ô∏è Time: 3.61 seconds\n",
      "\n",
      "Evaluating GradientBoosting...\n",
      "‚úÖ Best parameters: {'classifier': GradientBoostingClassifier(random_state=42), 'classifier__learning_rate': 0.1, 'classifier__n_estimators': 100}\n",
      "‚úÖ Cross-validation accuracy: 0.7295\n",
      "‚úÖ Validation accuracy: 0.7412\n",
      "‚è±Ô∏è Time: 2.94 seconds\n",
      "\n",
      "Evaluating AdaBoost...\n",
      "‚úÖ Best parameters: {'classifier': AdaBoostClassifier(random_state=42), 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 200}\n",
      "‚úÖ Cross-validation accuracy: 0.7190\n",
      "‚úÖ Validation accuracy: 0.7211\n",
      "‚è±Ô∏è Time: 2.83 seconds\n",
      "\n",
      "üìä Summary of Results (sorted by validation accuracy):\n",
      "Classifier           Val Accuracy    CV Accuracy     Time (s)  \n",
      "------------------------------------------------------------\n",
      "GradientBoosting     0.7412           0.7295           2.94\n",
      "RandomForest         0.7255           0.7182           3.61\n",
      "AdaBoost             0.7211           0.7190           2.83\n",
      "LogisticRegression   0.7205           0.7071           1.39\n",
      "SVC                  0.7205           0.7220           16.44\n",
      "\n",
      "üèÜ Best classifier: GradientBoosting\n",
      "‚úÖ Validation accuracy: 0.7412\n",
      "\n",
      "üìä Classification Report for GradientBoosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.79      0.75       799\n",
      "        True       0.77      0.69      0.73       793\n",
      "\n",
      "    accuracy                           0.74      1592\n",
      "   macro avg       0.74      0.74      0.74      1592\n",
      "weighted avg       0.74      0.74      0.74      1592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed training dataset\n",
    "df_train = pd.read_csv(\"cleaned/final_training_data_titlefeatures.csv\")\n",
    "\n",
    "# Apply frequency encoding to categorical variables\n",
    "for col in [\"director_id\", \"writer_id\"]:\n",
    "    freq_encoding = df_train[col].value_counts(normalize=True)\n",
    "    df_train[col] = df_train[col].map(freq_encoding)\n",
    "\n",
    "# Define Features & Target\n",
    "features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\", \"word_count\",\n",
    "           \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "X = df_train[features]\n",
    "y = df_train[\"label\"]  # Only train data has labels\n",
    "\n",
    "# Split training data into train (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "numeric_features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"word_count\",\n",
    "                   \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create base pipeline with preprocessing\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", None)  # Placeholder for classifier\n",
    "])\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"classifier\": [LogisticRegression(max_iter=1000, random_state=42)],\n",
    "        \"classifier__C\": [0.1, 1.0, 10.0],\n",
    "        \"classifier__solver\": [\"liblinear\", \"lbfgs\"]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"classifier\": [SVC(probability=True, random_state=42)],\n",
    "        \"classifier__C\": [0.1, 1.0, 10.0],\n",
    "        \"classifier__kernel\": [\"linear\", \"rbf\"]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"classifier\": [RandomForestClassifier(random_state=42)],\n",
    "        \"classifier__n_estimators\": [100, 200],\n",
    "        \"classifier__max_depth\": [None, 20]\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"classifier\": [GradientBoostingClassifier(random_state=42)],\n",
    "        \"classifier__n_estimators\": [100, 200],\n",
    "        \"classifier__learning_rate\": [0.01, 0.1]\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"classifier\": [AdaBoostClassifier(random_state=42)],\n",
    "        \"classifier__n_estimators\": [50, 100, 200],\n",
    "        \"classifier__learning_rate\": [0.01, 0.1, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform GridSearch for each classifier\n",
    "results = {}\n",
    "print(\"üîç Starting grid search across classifiers...\")\n",
    "\n",
    "for name, param_grid in classifiers.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Get best model\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"best_model\": best_model,\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"best_cv_score\": grid.best_score_,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"time\": time.time() - start_time\n",
    "    }\n",
    "\n",
    "    print(f\"‚úÖ Best parameters: {grid.best_params_}\")\n",
    "    print(f\"‚úÖ Cross-validation accuracy: {grid.best_score_:.4f}\")\n",
    "    print(f\"‚úÖ Validation accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"‚è±Ô∏è Time: {results[name]['time']:.2f} seconds\")\n",
    "\n",
    "# Print summary table sorted by validation accuracy\n",
    "print(\"\\nüìä Summary of Results (sorted by validation accuracy):\")\n",
    "print(f\"{'Classifier':<20} {'Val Accuracy':<15} {'CV Accuracy':<15} {'Time (s)':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, result in sorted(results.items(), key=lambda x: x[1][\"val_accuracy\"], reverse=True):\n",
    "    print(f\"{name:<20} {result['val_accuracy']:.4f}{' '*10} {result['best_cv_score']:.4f}{' '*10} {result['time']:.2f}\")\n",
    "\n",
    "# Get best model\n",
    "best_classifier = max(results.items(), key=lambda x: x[1][\"val_accuracy\"])\n",
    "best_name = best_classifier[0]\n",
    "best_result = best_classifier[1]\n",
    "\n",
    "print(f\"\\nüèÜ Best classifier: {best_name}\")\n",
    "print(f\"‚úÖ Validation accuracy: {best_result['val_accuracy']:.4f}\")\n",
    "\n",
    "# Detailed evaluation of best model\n",
    "y_val_pred = best_result[\"best_model\"].predict(X_val)\n",
    "print(f\"\\nüìä Classification Report for {best_name}:\\n\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b66a5609d456d8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:40.713441Z",
     "start_time": "2025-03-17T21:04:10.896536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.7450\n",
      "Stacking Classifier Accuracy: 0.7443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "# Create base models from your best performers\n",
    "gb = results[\"GradientBoosting\"][\"best_model\"]\n",
    "rf = results[\"RandomForest\"][\"best_model\"]\n",
    "svm = results[\"SVC\"][\"best_model\"]\n",
    "\n",
    "# Create voting ensemble\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('gb', gb), ('rf', rf), ('svm', svm)],\n",
    "    voting='soft'  # Use probability estimates\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "vote_acc = accuracy_score(y_val, voting_clf.predict(X_val))\n",
    "print(f\"Voting Classifier Accuracy: {vote_acc:.4f}\")\n",
    "\n",
    "# Create stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('gb', gb), ('rf', rf), ('svm', svm)],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "stack_acc = accuracy_score(y_val, stacking_clf.predict(X_val))\n",
    "print(f\"Stacking Classifier Accuracy: {stack_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
