{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to an in-memory DuckDB instance\n",
    "con = duckdb.connect(database=':memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "train_df = con.execute(\"SELECT * FROM 'imdb/train-*.csv'\").fetchdf()\n",
    "directors_df = con.execute(\"SELECT * FROM 'imdb/directing.json'\").fetchdf()\n",
    "writers_df = con.execute(\"SELECT * FROM 'imdb/writing.json'\").fetchdf()\n",
    "\n",
    "# Load rotten tomatoes CSV files\n",
    "rotten_movies = con.execute(\"SELECT * FROM 'rotten_tomatoes_movies.csv'\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tconst director_id\n",
      "0      0           0\n",
      "0      0           1\n",
      "0      0           2\n",
      "0      0           3\n",
      "0      0           4\n",
      "  tconst writer_id\n",
      "0   None      None\n",
      "1   None      None\n",
      "2   None      None\n",
      "3   None      None\n",
      "4   None      None\n"
     ]
    }
   ],
   "source": [
    "# Convert JSON-like strings to actual dictionaries\n",
    "def safe_json_loads(x):\n",
    "\ttry:\n",
    "\t\treturn json.loads(x) if isinstance(x, str) and x else x\n",
    "\texcept json.JSONDecodeError:\n",
    "\t\treturn None\n",
    "\n",
    "directors_df['movie'] = directors_df['movie'].apply(safe_json_loads)\n",
    "directors_df['director'] = directors_df['director'].apply(safe_json_loads)\n",
    "\n",
    "writers_df['movie'] = writers_df['movie'].apply(safe_json_loads)\n",
    "writers_df['writer'] = writers_df['writer'].apply(safe_json_loads)\n",
    "\n",
    "# Explode dictionaries into separate rows\n",
    "directors_expanded = directors_df.explode('movie').explode('director')\n",
    "directors_expanded.rename(columns={'movie': 'tconst', 'director': 'director_id'}, inplace=True)\n",
    "\n",
    "writers_expanded = writers_df.explode('movie').explode('writer')\n",
    "writers_expanded.rename(columns={'movie': 'tconst', 'writer': 'writer_id'}, inplace=True)\n",
    "\n",
    "# Check the cleaned data\n",
    "print(directors_expanded.head())\n",
    "print(writers_expanded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base tables in DuckDB from pandas DataFrames\n",
    "con.execute(\"CREATE TABLE train_df AS SELECT * FROM train_df\")\n",
    "con.execute(\"CREATE TABLE directors_expanded AS SELECT * FROM directors_expanded\")\n",
    "con.execute(\"CREATE TABLE writers_expanded AS SELECT * FROM writers_expanded\")\n",
    "\n",
    "# rotten tomatoes update\n",
    "con.execute(\"CREATE TABLE rotten_movies AS SELECT * FROM rotten_movies\")\n",
    "\n",
    "# Create indexes for faster lookup\n",
    "con.execute(\"CREATE INDEX train_df_tconst_idx ON train_df (tconst);\")\n",
    "con.execute(\"CREATE INDEX directors_expanded_tconst_idx ON directors_expanded (tconst);\")\n",
    "con.execute(\"CREATE INDEX writers_expanded_tconst_idx ON writers_expanded (tconst);\")\n",
    "\n",
    "# rotten tomatoes update\n",
    "con.execute(\"CREATE INDEX rotten_movies_rotten_tomatoes_link ON rotten_movies (rotten_tomatoes_link);\")\n",
    "\n",
    "# Join tables\n",
    "movies_df = con.execute(\"\"\"\n",
    "    SELECT t.*, d.director_id, w.writer_id\n",
    "    FROM train_df t\n",
    "    LEFT JOIN directors_expanded d ON t.tconst = d.tconst\n",
    "    LEFT JOIN writers_expanded w ON t.tconst = w.tconst\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "final_movies_df = con.execute(\"\"\" \n",
    "    SELECT m.*, r.tomatometer_rating, r.tomatometer_count, r.audience_rating, r.audience_count\n",
    "    FROM movies_df m\n",
    "    LEFT JOIN rotten_movies r ON m.primaryTitle = r.movie_title\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column0     tconst                                       primaryTitle  \\\n",
      "0     5326  tt0814255  Percy Jackson & the Olympians: The Lightning T...   \n",
      "1     4584  tt0381849                                       3:10 to Yuma   \n",
      "2     4593  tt0382628                                         Dark Water   \n",
      "3      298  tt0033873                                           Man Hunt   \n",
      "4      189  tt0028773                                           Dead End   \n",
      "\n",
      "  originalTitle startYear endYear runtimeMinutes  numVotes  label  \\\n",
      "0          None      2010      \\N            118  183678.0  False   \n",
      "1          None        \\N    2007            122  300411.0   True   \n",
      "2          None      2005      \\N            105   61511.0  False   \n",
      "3      Man Hunt        \\N    1941            105    5231.0   True   \n",
      "4      Dead End      1937      \\N             93       NaN   True   \n",
      "\n",
      "   director_id  writer_id  tomatometer_rating  tomatometer_count  \\\n",
      "0         <NA>       <NA>                  49                149   \n",
      "1         <NA>       <NA>                  96                 28   \n",
      "2         <NA>       <NA>                  80                 15   \n",
      "3         <NA>       <NA>                  92                 12   \n",
      "4         <NA>       <NA>                  75                  8   \n",
      "\n",
      "   audience_rating  audience_count  \n",
      "0               53          254421  \n",
      "1               79            9243  \n",
      "2               66           21475  \n",
      "3               75             554  \n",
      "4               60           10373  \n"
     ]
    }
   ],
   "source": [
    "# Check the final dataset\n",
    "print(final_movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8224 entries, 0 to 8223\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   column0             8224 non-null   int64  \n",
      " 1   tconst              8224 non-null   object \n",
      " 2   primaryTitle        8224 non-null   object \n",
      " 3   originalTitle       4112 non-null   object \n",
      " 4   startYear           8224 non-null   object \n",
      " 5   endYear             8224 non-null   object \n",
      " 6   runtimeMinutes      8224 non-null   object \n",
      " 7   numVotes            7406 non-null   float64\n",
      " 8   label               8224 non-null   bool   \n",
      " 9   director_id         0 non-null      Int32  \n",
      " 10  writer_id           0 non-null      Int32  \n",
      " 11  tomatometer_rating  2735 non-null   Int64  \n",
      " 12  tomatometer_count   2735 non-null   Int64  \n",
      " 13  audience_rating     2730 non-null   Int64  \n",
      " 14  audience_count      2730 non-null   Int64  \n",
      "dtypes: Int32(2), Int64(4), bool(1), float64(1), int64(1), object(6)\n",
      "memory usage: 891.6+ KB\n"
     ]
    }
   ],
   "source": [
    "final_movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oisin\\AppData\\Local\\Temp\\ipykernel_2276\\1990886512.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_movies_df['startYear'].fillna(final_movies_df['endYear'], inplace=True)\n",
      "C:\\Users\\oisin\\AppData\\Local\\Temp\\ipykernel_2276\\1990886512.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_movies_df['primaryTitle'].fillna(final_movies_df['originalTitle'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Convert startYear to integer and then to movie age\n",
    "final_movies_df['startYear'] = pd.to_numeric(final_movies_df['startYear'], errors='coerce')\n",
    "final_movies_df['endYear'] = pd.to_numeric(final_movies_df['endYear'], errors='coerce')\n",
    "\n",
    "# If startYear is empty or NaN, fill it with endYear\n",
    "final_movies_df['startYear'].fillna(final_movies_df['endYear'], inplace=True)\n",
    "\n",
    "# If primaryTitle is empty or NaN, fill it with originalTitle\n",
    "final_movies_df['primaryTitle'].fillna(final_movies_df['originalTitle'], inplace=True)\n",
    "\n",
    "# Remove the columns originalTitle and endYear\n",
    "final_movies_df.drop(columns=['originalTitle', 'endYear'], inplace=True)\n",
    "\n",
    "final_movies_df['movie_age'] = 2025 - final_movies_df['startYear']\n",
    "\n",
    "# Log-transform numVotes\n",
    "final_movies_df['log_numVotes'] = np.log1p(final_movies_df['numVotes'])\n",
    "\n",
    "# Categorize runtime\n",
    "final_movies_df['runtime_category'] = pd.cut(\n",
    "    pd.to_numeric(movies_df['runtimeMinutes'], errors='coerce'),\n",
    "    bins=[0, 60, 90, 120, 180, np.inf],\n",
    "    labels=['short', 'medium', 'long', 'very long', 'epic']\n",
    ")\n",
    "\n",
    "final_movies_df.to_csv(\"cleaned_imdb_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"cleaned_imdb_data.csv\")\n",
    "\n",
    "# Prepare features and labels\n",
    "X = df[['movie_age', 'log_numVotes', 'tomatometer_rating', 'tomatometer_count', 'audience_rating', 'audience_count']]  # Add more features as needed\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6954407294832827\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- audience_count\n- audience_rating\n- tomatometer_count\n- tomatometer_rating\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X_test_hidden \u001b[38;5;241m=\u001b[39m test_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_age\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_numVotes\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m---> 15\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m### VALIDATION SUBMISSION ###\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m val_df \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb/validation_hidden.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfetchdf()\n",
      "File \u001b[1;32mc:\\Users\\oisin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\oisin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\oisin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\oisin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32mc:\\Users\\oisin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- audience_count\n- audience_rating\n- tomatometer_count\n- tomatometer_rating\n"
     ]
    }
   ],
   "source": [
    "### TEST SUBMISSION ###\n",
    "\n",
    "# Load test data\n",
    "test_df = con.execute(\"SELECT * FROM 'imdb/test_hidden.csv'\").fetchdf()\n",
    "\n",
    "# Convert startYear to numeric\n",
    "test_df['startYear'] = pd.to_numeric(test_df['startYear'], errors='coerce')\n",
    "\n",
    "# Apply same feature transformations\n",
    "test_df['movie_age'] = 2025 - test_df['startYear']\n",
    "test_df['log_numVotes'] = np.log1p(test_df['numVotes'])\n",
    "\n",
    "# Predict\n",
    "X_test_hidden = test_df[['movie_age', 'log_numVotes']]\n",
    "test_df['predicted_label'] = clf.predict(X_test_hidden)\n",
    "\n",
    "### VALIDATION SUBMISSION ###\n",
    "# Load test data\n",
    "val_df = con.execute(\"SELECT * FROM 'imdb/validation_hidden.csv'\").fetchdf()\n",
    "\n",
    "# Convert startYear to numeric\n",
    "val_df['startYear'] = pd.to_numeric(val_df['startYear'], errors='coerce')\n",
    "\n",
    "# Apply same feature transformations\n",
    "val_df['movie_age'] = 2025 - val_df['startYear']\n",
    "val_df['log_numVotes'] = np.log1p(val_df['numVotes'])\n",
    "\n",
    "# Predict\n",
    "X_val_hidden = val_df[['movie_age', 'log_numVotes']]\n",
    "val_df['predicted_label'] = clf.predict(X_val_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for submission\n",
    "test_df[['predicted_label']].to_csv(\"submission_test.csv\", index=False, header=False)\n",
    "\n",
    "# Save for submission\n",
    "validation_df[['predicted_label']].to_csv(\"submission_validation.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
