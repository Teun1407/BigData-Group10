{
 "cells": [
  {
   "cell_type": "code",
   "id": "8224cfca-63cd-4397-8a7d-892f1b0577d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:36.202640Z",
     "start_time": "2025-03-17T21:06:35.836977Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "from textblob import TextBlob\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "# from xgboost import XGBClassifier\n",
    "from scipy.stats import trim_mean\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:36.207492Z",
     "start_time": "2025-03-17T21:06:36.205263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_runtime(df, k=0.1):\n",
    "    \"\"\"\n",
    "    Preprocesses the runtime information, including handling extreme values\n",
    "    (movies with runtime > 1000 minutes, possibly in seconds or hours).\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame containing the movie data.\n",
    "    - k: Proportion of values to trim from each end when computing the trimmed mean.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with cleaned runtime information.\n",
    "    \"\"\"\n",
    "    # First convert to numeric, coercing errors to NaN\n",
    "    df[\"runtimeMinutes\"] = pd.to_numeric(df[\"runtimeMinutes\"], errors='coerce')\n",
    "\n",
    "    # Compute k-trimmed mean for runtimeMinutes (ignoring NaN values)\n",
    "    trimmed_mean_runtime = trim_mean(df[\"runtimeMinutes\"].dropna().values, proportiontocut=k)\n",
    "    print(trimmed_mean_runtime)\n",
    "\n",
    "    # Fill missing values with trimmed mean\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].fillna(trimmed_mean_runtime)\n",
    "\n",
    "    # Handle movies that are possibly in seconds or hours\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].apply(lambda x: x / 60 if pd.notna(x) and x > 1000 else x)  # Convert seconds to minutes\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].apply(lambda x: x * 60 if pd.notna(x) and x < 5 else x)  # Convert minutes to hours if under 5 mins\n",
    "\n",
    "    # Now convert to int (after handling extreme values and filling NaNs)\n",
    "    df[\"runtimeMinutes\"] = df[\"runtimeMinutes\"].round().astype(int)\n",
    "\n",
    "    return df"
   ],
   "id": "de8bce70a1f5acf2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b1588593-ab24-49a5-bb51-d755af920960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:36.288475Z",
     "start_time": "2025-03-17T21:06:36.283702Z"
    }
   },
   "source": [
    "def preprocess_imdb_data(data_path, directors_path, writers_path):\n",
    "    \"\"\"\n",
    "    General preprocessing pipeline for IMDB data.\n",
    "    \n",
    "    Arguments:\n",
    "    - data_path: Path to the train/test/validation data CSV file.\n",
    "    - directors_path: Path to the directing.json file.\n",
    "    - writers_path: Path to the writing.json file.\n",
    "    \n",
    "    Returns:\n",
    "    - Cleaned Pandas DataFrame ready for model training or prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Load main dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Step 2: Load JSON files (Directors & Writers)\n",
    "    df_directors = pd.read_json(directors_path)\n",
    "    df_writers = pd.read_json(writers_path)\n",
    "\n",
    "    # Step 3: Rename columns for consistency\n",
    "    df_directors.rename(columns={\"movie\": \"tconst\", \"director\": \"director_id\"}, inplace=True)\n",
    "    df_writers.rename(columns={\"movie\": \"tconst\", \"writer\": \"writer_id\"}, inplace=True)\n",
    "\n",
    "    # Step 4: Convert nested JSON fields into strings\n",
    "    df_directors[\"director_id\"] = df_directors[\"director_id\"].astype(str)\n",
    "    df_writers[\"writer_id\"] = df_writers[\"writer_id\"].astype(str)\n",
    "\n",
    "    # Step 5: Merge main dataset with Directors & Writers using DuckDB\n",
    "    con = duckdb.connect()\n",
    "    con.register(\"movies\", df)\n",
    "    con.register(\"directors\", df_directors)\n",
    "    con.register(\"writers\", df_writers)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        movies.*, \n",
    "        directors.director_id, \n",
    "        writers.writer_id\n",
    "    FROM movies\n",
    "    LEFT JOIN directors ON movies.tconst = directors.tconst\n",
    "    LEFT JOIN writers ON movies.tconst = writers.tconst\n",
    "    \"\"\"\n",
    "\n",
    "    df = con.execute(query).fetchdf()\n",
    "    con.close()\n",
    "\n",
    "    # Step 6: Create column year from startYear and endYear\n",
    "    df['startYear'] = df['startYear'].replace('\\\\N', np.nan).astype(float)\n",
    "    df['endYear'] = df['endYear'].replace('\\\\N', np.nan).astype(float)\n",
    "    df['Year'] = df['startYear'].fillna(df['endYear'])\n",
    "\n",
    "    # Step 7: Clean title names\n",
    "    def normalize_text(text):\n",
    "        if pd.isna(text):  # Handle missing values\n",
    "            return \"\"\n",
    "        text = str(text)\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')  # Remove accents\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "        return text.strip()\n",
    "\n",
    "    def clean_titles(row):\n",
    "        primary = row['primaryTitle'] if pd.notna(row['primaryTitle']) else ''\n",
    "        original = row['originalTitle'] if pd.notna(row['originalTitle']) else ''\n",
    "\n",
    "        if not primary:\n",
    "            primary = original\n",
    "\n",
    "        cleaned_title = normalize_text(primary)\n",
    "\n",
    "        return cleaned_title if cleaned_title else \"Unknown Title\"\n",
    "\n",
    "    df['primaryTitle'] = df.apply(clean_titles, axis=1)\n",
    "    df.rename(columns={'primaryTitle': 'movieTitle'}, inplace=True)\n",
    "\n",
    "    # Step 8: Compute Title Uniqueness Score\n",
    "    title_counts = df[\"movieTitle\"].value_counts()\n",
    "    df[\"title_uniqueness\"] = df[\"movieTitle\"].apply(lambda x: 1 / title_counts[x] if title_counts[x] > 1 else 1)\n",
    "\n",
    "    # Step 9: Compute Sentiment Score\n",
    "    df[\"sentiment_score\"] = df[\"movieTitle\"].astype(str).apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "    # Step 10: Count words in each title\n",
    "    df[\"word_count\"] = df[\"movieTitle\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "    #Step 11 title lenght\n",
    "    df[\"title_word_length_std\"] = df[\"movieTitle\"].apply(lambda x: np.std([len(word) for word in x.split()]) if len(x.split()) > 1 else 0)\n",
    "    \n",
    "    # Step 12: Drop unnecessary columns\n",
    "    columns_to_drop = [\"originalTitle\", \"endYear\", \"startYear\", \"Unnamed: 0\"]\n",
    "    df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "    # Step 14: Handle missing values\n",
    "    df = preprocess_runtime(df, 0.1)\n",
    "\n",
    "    # Step 15: Fill missing values for numVotes\n",
    "    trimmed_mean_votes = trim_mean(df[\"numVotes\"].dropna(), proportiontocut=0.1)\n",
    "    df[\"numVotes\"] = df[\"numVotes\"].fillna(trimmed_mean_votes)\n",
    "\n",
    "\n",
    "    # Step 16: Fill missing values for director_id and writer_id\n",
    "    df[\"director_id\"] = df[\"director_id\"].fillna(\"unknown\")\n",
    "    df[\"writer_id\"] = df[\"writer_id\"].fillna(\"unknown\")\n",
    "\n",
    "    # Step 13: Ensure correct data types\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"numVotes\"] = df[\"numVotes\"].astype(int)\n",
    "\n",
    "    # Step 17: Ensure each `tconst` is unique\n",
    "    df = df.groupby(\"tconst\").first().reset_index()\n",
    "    \n",
    "    return df\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "6b782cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:37.987480Z",
     "start_time": "2025-03-17T21:06:36.295754Z"
    }
   },
   "source": [
    "# Define file paths\n",
    "# Define the base directory\n",
    "base_data_dir = os.path.join(os.getcwd(), \"imdb\")\n",
    "\n",
    "# Generate the list of train file paths\n",
    "train_files = [os.path.join(base_data_dir, f) for f in os.listdir(base_data_dir) if f.startswith(\"train-\") and f.endswith(\".csv\")]\n",
    "\n",
    "# Define paths for directors and writers files\n",
    "directors_path = os.path.join(base_data_dir, \"directing.json\")\n",
    "writers_path = os.path.join(base_data_dir, \"writing.json\")\n",
    "\n",
    "# Load JSON files (Directors & Writers)\n",
    "df_directors = pd.read_json(directors_path)\n",
    "df_writers = pd.read_json(writers_path)\n",
    "\n",
    "# Preprocess and merge all training data\n",
    "df_train = pd.concat([preprocess_imdb_data(file, directors_path, writers_path) for file in train_files], ignore_index=True)\n",
    "\n",
    "# Preprocess validation and test data\n",
    "df_val = preprocess_imdb_data(os.path.join(base_data_dir, \"validation_hidden.csv\"), directors_path, writers_path)\n",
    "df_test = preprocess_imdb_data(os.path.join(base_data_dir, \"test_hidden.csv\"), directors_path, writers_path)\n",
    "\n",
    "# Save cleaned datasets\n",
    "df_train.to_csv(\"cleaned/final_training_data_titlefeatures.csv\", index=False)\n",
    "df_val.to_csv(\"cleaned/final_validation_data_titlefeatures.csv\", index=False)\n",
    "df_test.to_csv(\"cleaned/final_test_data_titlefeatures.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ All datasets have been preprocessed and saved!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.17957746478874\n",
      "103.04074241738343\n",
      "99.50600096015363\n",
      "99.8041928721174\n",
      "103.14328808446456\n",
      "109.99336650082918\n",
      "102.62376237623762\n",
      "107.98286604361371\n",
      "100.43593670239919\n",
      "102.08707607699358\n",
      "\n",
      "‚úÖ All datasets have been preprocessed and saved!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:38.006849Z",
     "start_time": "2025-03-17T21:06:37.995760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_unique_ratio(df, columns=None):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of unique rows to total rows in the DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame to analyze\n",
    "    - columns: List of columns to consider (if None, uses all columns)\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing unique ratio metrics\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "\n",
    "    total_rows = len(df)\n",
    "    unique_rows = len(df[columns].drop_duplicates())\n",
    "    ratio = unique_rows / total_rows\n",
    "\n",
    "    metrics = {\n",
    "        \"total_rows\": total_rows,\n",
    "        \"unique_rows\": unique_rows,\n",
    "        \"unique_ratio\": ratio\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Add this after your data preprocessing\n",
    "print(\"\\nüîç Analyzing unique row ratios...\")\n",
    "\n",
    "# Calculate ratios for all datasets\n",
    "train_metrics = calculate_unique_ratio(df_train)\n",
    "val_metrics = calculate_unique_ratio(df_val)\n",
    "test_metrics = calculate_unique_ratio(df_test)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nUnique Row Analysis:\")\n",
    "print(f\"Training Data:\")\n",
    "print(f\"  - Total Rows: {train_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {train_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {train_metrics['unique_ratio']:.2%}\")\n",
    "\n",
    "print(f\"\\nValidation Data:\")\n",
    "print(f\"  - Total Rows: {val_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {val_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {val_metrics['unique_ratio']:.2%}\")\n",
    "\n",
    "print(f\"\\nTest Data:\")\n",
    "print(f\"  - Total Rows: {test_metrics['total_rows']:,}\")\n",
    "print(f\"  - Unique Rows: {test_metrics['unique_rows']:,}\")\n",
    "print(f\"  - Unique Ratio: {test_metrics['unique_ratio']:.2%}\")"
   ],
   "id": "2d42f0eed525e31a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Analyzing unique row ratios...\n",
      "\n",
      "Unique Row Analysis:\n",
      "Training Data:\n",
      "  - Total Rows: 7,959\n",
      "  - Unique Rows: 7,959\n",
      "  - Unique Ratio: 100.00%\n",
      "\n",
      "Validation Data:\n",
      "  - Total Rows: 955\n",
      "  - Unique Rows: 955\n",
      "  - Unique Ratio: 100.00%\n",
      "\n",
      "Test Data:\n",
      "  - Total Rows: 1,086\n",
      "  - Unique Rows: 1,086\n",
      "  - Unique Ratio: 100.00%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:38.024352Z",
     "start_time": "2025-03-17T21:06:38.014177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def handle_duplicates(df, groupby_cols=None, agg_strategy=None):\n",
    "    \"\"\"\n",
    "    Handle duplicate rows using specified aggregation strategies.\n",
    "\n",
    "    Arguments:\n",
    "    - df: DataFrame to process\n",
    "    - groupby_cols: List of columns to identify duplicates (default: all columns except label)\n",
    "    - agg_strategy: Dictionary of column names and aggregation functions\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with handled duplicates\n",
    "    \"\"\"\n",
    "    if groupby_cols is None:\n",
    "        groupby_cols = [col for col in df.columns if col != 'label']\n",
    "\n",
    "    if agg_strategy is None:\n",
    "        agg_strategy = {\n",
    "            'runtimeMinutes': 'mean',\n",
    "            'numVotes': 'sum',\n",
    "            'startYear': 'first',\n",
    "            'director_id': 'first',\n",
    "            'writer_id': 'first',\n",
    "            'label': 'mode'\n",
    "        }\n",
    "\n",
    "    # Count occurrences before deduplication\n",
    "    total_rows = len(df)\n",
    "    unique_rows = len(df[groupby_cols].drop_duplicates())\n",
    "\n",
    "    if total_rows == unique_rows:\n",
    "        print(\"No duplicates found!\")\n",
    "        return df\n",
    "\n",
    "    print(f\"\\nFound {total_rows - unique_rows:,} duplicate rows\")\n",
    "    print(f\"Unique ratio before: {(unique_rows/total_rows):.2%}\")\n",
    "\n",
    "    # Handle duplicates using aggregation\n",
    "    df_cleaned = df.groupby(groupby_cols, as_index=False).agg(agg_strategy)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Rows after duplicate handling: {len(df_cleaned):,}\")\n",
    "    print(f\"Unique ratio after: {(len(df_cleaned)/total_rows):.2%}\")\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Handle duplicates\n",
    "print(\"\\nüîç Handling duplicates...\")\n",
    "df_train = handle_duplicates(df_train)\n",
    "df_val = handle_duplicates(df_val)\n",
    "df_test = handle_duplicates(df_test)"
   ],
   "id": "e8e86c7b646b0ea0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Handling duplicates...\n",
      "No duplicates found!\n",
      "No duplicates found!\n",
      "No duplicates found!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "9a4931c9-d175-44ed-8e4d-2963d66be56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:38.032341Z",
     "start_time": "2025-03-17T21:06:38.030804Z"
    }
   },
   "source": [
    "# # Define Features & Target\n",
    "# features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\", \"word_count\"]\n",
    "# X_train = df_train[features]\n",
    "# y_train = df_train[\"label\"]\n",
    "# X_val = df_val[features]\n",
    "# X_test = df_test[features]\n",
    "\n",
    "# # Preprocessing Pipeline\n",
    "# numeric_features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"word_count\"]\n",
    "# categorical_features = [\"director_id\", \"writer_id\"]\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", StandardScaler(), numeric_features),\n",
    "#         (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Train Logistic Regression Model\n",
    "# model = Pipeline([\n",
    "#     (\"preprocessing\", preprocessor),\n",
    "#     (\"classifier\", SVC(kernel=\"linear\", probability=True))\n",
    "# ])\n",
    "\n",
    "# print(\"üîπ Training model on full training data...\")\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Generate Predictions\n",
    "# y_val_pred = model.predict(X_val)\n",
    "# y_test_pred = model.predict(X_test)\n",
    "\n",
    "# # Save predictions in required format (no headers, single column)\n",
    "# pd.DataFrame(y_val_pred).to_csv(\"submissions/validation_predictions_SVM.csv\", index=False, header=False)\n",
    "# pd.DataFrame(y_test_pred).to_csv(\"submissions/test_predictions_SVM.csv\", index=False, header=False)\n",
    "\n",
    "# print(\"‚úÖ Predictions saved for submission!\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "90c25ca6-e414-426c-9b66-901333d1d979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:40.403506Z",
     "start_time": "2025-03-17T21:06:38.038952Z"
    }
   },
   "source": [
    "# Load preprocessed training dataset\n",
    "df_train = pd.read_csv(\"cleaned/final_training_data_titlefeatures.csv\")\n",
    "\n",
    "# Apply frequency encoding to categorical variables\n",
    "for col in [\"director_id\", \"writer_id\"]:\n",
    "    freq_encoding = df_train[col].value_counts(normalize=True)\n",
    "    df_train[col] = df_train[col].map(freq_encoding)\n",
    "\n",
    "# Define Features & Target\n",
    "features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\", \"word_count\", \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "X = df_train[features]\n",
    "y = df_train[\"label\"]  # Only train data has labels\n",
    "\n",
    "# **NEW: Split training data into train (80%) and validation (20%)**\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing Pipeline (same for all models)\n",
    "numeric_features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"word_count\", \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ]\n",
    ")\n",
    "# Create pipeline with preprocessing\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", SVC(kernel=\"linear\", probability=True))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"‚úÖ Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"‚úÖ Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"üìä Classification Report for:\\n\", classification_report(y_val, y_val_pred))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training Accuracy: 0.7140\n",
      "‚úÖ Validation Accuracy: 0.7142\n",
      "üìä Classification Report for:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.80      0.74       799\n",
      "        True       0.76      0.63      0.69       793\n",
      "\n",
      "    accuracy                           0.71      1592\n",
      "   macro avg       0.72      0.71      0.71      1592\n",
      "weighted avg       0.72      0.71      0.71      1592\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ed02ac3f-4944-4f00-ad28-823e85a97f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:07:54.381202Z",
     "start_time": "2025-03-17T21:07:27.133151Z"
    }
   },
   "source": [
    "# Load preprocessed training dataset\n",
    "df_train = pd.read_csv(\"cleaned/final_training_data_titlefeatures.csv\")\n",
    "\n",
    "# Apply frequency encoding to categorical variables\n",
    "for col in [\"director_id\", \"writer_id\"]:\n",
    "    freq_encoding = df_train[col].value_counts(normalize=True)\n",
    "    df_train[col] = df_train[col].map(freq_encoding)\n",
    "\n",
    "# Define Features & Target\n",
    "features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"director_id\", \"writer_id\", \"word_count\",\n",
    "           \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "X = df_train[features]\n",
    "y = df_train[\"label\"]  # Only train data has labels\n",
    "\n",
    "# Split training data into train (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "numeric_features = [\"Year\", \"runtimeMinutes\", \"numVotes\", \"word_count\",\n",
    "                   \"title_uniqueness\", \"title_word_length_std\", \"sentiment_score\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create base pipeline with preprocessing\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", None)  # Placeholder for classifier\n",
    "])\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"classifier\": [LogisticRegression(max_iter=1000, random_state=42)],\n",
    "        \"classifier__C\": [0.1, 1.0, 10.0],\n",
    "        \"classifier__solver\": [\"liblinear\", \"lbfgs\"]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"classifier\": [SVC(probability=True, random_state=42)],\n",
    "        \"classifier__C\": [0.1, 1.0, 10.0],\n",
    "        \"classifier__kernel\": [\"linear\", \"rbf\"]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"classifier\": [RandomForestClassifier(random_state=42)],\n",
    "        \"classifier__n_estimators\": [100, 200],\n",
    "        \"classifier__max_depth\": [None, 20]\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"classifier\": [GradientBoostingClassifier(random_state=42)],\n",
    "        \"classifier__n_estimators\": [100, 200],\n",
    "        \"classifier__learning_rate\": [0.01, 0.1]\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"classifier\": [AdaBoostClassifier(random_state=42)],\n",
    "        \"classifier__n_estimators\": [50, 100, 200],\n",
    "        \"classifier__learning_rate\": [0.01, 0.1, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform GridSearch for each classifier\n",
    "results = {}\n",
    "print(\"üîç Starting grid search across classifiers...\")\n",
    "\n",
    "for name, param_grid in classifiers.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Get best model\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"best_model\": best_model,\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"best_cv_score\": grid.best_score_,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"time\": time.time() - start_time\n",
    "    }\n",
    "\n",
    "    print(f\"‚úÖ Best parameters: {grid.best_params_}\")\n",
    "    print(f\"‚úÖ Cross-validation accuracy: {grid.best_score_:.4f}\")\n",
    "    print(f\"‚úÖ Validation accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"‚è±Ô∏è Time: {results[name]['time']:.2f} seconds\")\n",
    "\n",
    "# Print summary table sorted by validation accuracy\n",
    "print(\"\\nüìä Summary of Results (sorted by validation accuracy):\")\n",
    "print(f\"{'Classifier':<20} {'Val Accuracy':<15} {'CV Accuracy':<15} {'Time (s)':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, result in sorted(results.items(), key=lambda x: x[1][\"val_accuracy\"], reverse=True):\n",
    "    print(f\"{name:<20} {result['val_accuracy']:.4f}{' '*10} {result['best_cv_score']:.4f}{' '*10} {result['time']:.2f}\")\n",
    "\n",
    "# Get best model\n",
    "best_classifier = max(results.items(), key=lambda x: x[1][\"val_accuracy\"])\n",
    "best_name = best_classifier[0]\n",
    "best_result = best_classifier[1]\n",
    "\n",
    "print(f\"\\nüèÜ Best classifier: {best_name}\")\n",
    "print(f\"‚úÖ Validation accuracy: {best_result['val_accuracy']:.4f}\")\n",
    "\n",
    "# Detailed evaluation of best model\n",
    "y_val_pred = best_result[\"best_model\"].predict(X_val)\n",
    "print(f\"\\nüìä Classification Report for {best_name}:\\n\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting grid search across classifiers...\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "‚úÖ Best parameters: {'classifier': LogisticRegression(max_iter=1000, random_state=42), 'classifier__C': 10.0, 'classifier__solver': 'liblinear'}\n",
      "‚úÖ Cross-validation accuracy: 0.7071\n",
      "‚úÖ Validation accuracy: 0.7205\n",
      "‚è±Ô∏è Time: 1.39 seconds\n",
      "\n",
      "Evaluating SVC...\n",
      "‚úÖ Best parameters: {'classifier': SVC(probability=True, random_state=42), 'classifier__C': 10.0, 'classifier__kernel': 'rbf'}\n",
      "‚úÖ Cross-validation accuracy: 0.7220\n",
      "‚úÖ Validation accuracy: 0.7205\n",
      "‚è±Ô∏è Time: 16.44 seconds\n",
      "\n",
      "Evaluating RandomForest...\n",
      "‚úÖ Best parameters: {'classifier': RandomForestClassifier(random_state=42), 'classifier__max_depth': 20, 'classifier__n_estimators': 100}\n",
      "‚úÖ Cross-validation accuracy: 0.7182\n",
      "‚úÖ Validation accuracy: 0.7255\n",
      "‚è±Ô∏è Time: 3.61 seconds\n",
      "\n",
      "Evaluating GradientBoosting...\n",
      "‚úÖ Best parameters: {'classifier': GradientBoostingClassifier(random_state=42), 'classifier__learning_rate': 0.1, 'classifier__n_estimators': 100}\n",
      "‚úÖ Cross-validation accuracy: 0.7295\n",
      "‚úÖ Validation accuracy: 0.7412\n",
      "‚è±Ô∏è Time: 2.94 seconds\n",
      "\n",
      "Evaluating AdaBoost...\n",
      "‚úÖ Best parameters: {'classifier': AdaBoostClassifier(random_state=42), 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 200}\n",
      "‚úÖ Cross-validation accuracy: 0.7190\n",
      "‚úÖ Validation accuracy: 0.7211\n",
      "‚è±Ô∏è Time: 2.83 seconds\n",
      "\n",
      "üìä Summary of Results (sorted by validation accuracy):\n",
      "Classifier           Val Accuracy    CV Accuracy     Time (s)  \n",
      "------------------------------------------------------------\n",
      "GradientBoosting     0.7412           0.7295           2.94\n",
      "RandomForest         0.7255           0.7182           3.61\n",
      "AdaBoost             0.7211           0.7190           2.83\n",
      "LogisticRegression   0.7205           0.7071           1.39\n",
      "SVC                  0.7205           0.7220           16.44\n",
      "\n",
      "üèÜ Best classifier: GradientBoosting\n",
      "‚úÖ Validation accuracy: 0.7412\n",
      "\n",
      "üìä Classification Report for GradientBoosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.79      0.75       799\n",
      "        True       0.77      0.69      0.73       793\n",
      "\n",
      "    accuracy                           0.74      1592\n",
      "   macro avg       0.74      0.74      0.74      1592\n",
      "weighted avg       0.74      0.74      0.74      1592\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:06:40.713441Z",
     "start_time": "2025-03-17T21:04:10.896536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "# Create base models from your best performers\n",
    "gb = results[\"GradientBoosting\"][\"best_model\"]\n",
    "rf = results[\"RandomForest\"][\"best_model\"]\n",
    "svm = results[\"SVC\"][\"best_model\"]\n",
    "\n",
    "# Create voting ensemble\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('gb', gb), ('rf', rf), ('svm', svm)],\n",
    "    voting='soft'  # Use probability estimates\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "vote_acc = accuracy_score(y_val, voting_clf.predict(X_val))\n",
    "print(f\"Voting Classifier Accuracy: {vote_acc:.4f}\")\n",
    "\n",
    "# Create stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('gb', gb), ('rf', rf), ('svm', svm)],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "stack_acc = accuracy_score(y_val, stacking_clf.predict(X_val))\n",
    "print(f\"Stacking Classifier Accuracy: {stack_acc:.4f}\")"
   ],
   "id": "b66a5609d456d8e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.7450\n",
      "Stacking Classifier Accuracy: 0.7443\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
